{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11739593,
          "sourceType": "datasetVersion",
          "datasetId": 5773627
        },
        {
          "sourceId": 251269321,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav172/Invoice-Fraud-Detection-Computer-Vision-/blob/main/InvoiceFraudDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "eVg0TSZdnfRw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "osamahosamabdellatif_high_quality_invoice_images_for_ocr_path = kagglehub.dataset_download('osamahosamabdellatif/high-quality-invoice-images-for-ocr')\n",
        "pranav1718_invoicefrauddetection_path = kagglehub.notebook_output_download('pranav1718/invoicefrauddetection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "8IirFLcenfR1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# STEP 1: RESTORE SAVED MODELS\n",
        "# =======================================================\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- PASTE YOUR CORRECT PATH HERE ---\n",
        "# Based on your screenshot, the models are in the root of your notebook's output directory.\n",
        "# Find the directory named after your notebook in the \"Input\" panel and copy its path.\n",
        "INPUT_MODEL_PATH = \"/kaggle/input/invoicefrauddetection/\" # <-- THIS IS THE MOST LIKELY PATH\n",
        "OUTPUT_MODEL_PATH = \"/kaggle/working/\"\n",
        "\n",
        "print(f\"Attempting to copy models from: {INPUT_MODEL_PATH}\")\n",
        "\n",
        "try:\n",
        "    # Create the destination directory if it doesn't exist\n",
        "    os.makedirs(OUTPUT_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "    # Copy the model files\n",
        "    shutil.copy(os.path.join(INPUT_MODEL_PATH, \"MobileNetV2_best.h5\"), OUTPUT_MODEL_PATH)\n",
        "    shutil.copy(os.path.join(INPUT_MODEL_PATH, \"DenseNet121_best.h5\"), OUTPUT_MODEL_PATH)\n",
        "\n",
        "    print(\"Models restored successfully!\")\n",
        "    print(\"Files in current working directory:\", os.listdir(OUTPUT_MODEL_PATH))\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nERROR: Could not find the model files.\")\n",
        "    print(\"If this fails, please find the directory named 'invoicefrauddetection' (or similar) in your 'Input' panel, right-click it, copy the path, and paste it into the INPUT_MODEL_PATH variable.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T23:31:41.938948Z",
          "iopub.execute_input": "2025-07-18T23:31:41.939286Z",
          "iopub.status.idle": "2025-07-18T23:31:41.948765Z",
          "shell.execute_reply.started": "2025-07-18T23:31:41.939261Z",
          "shell.execute_reply": "2025-07-18T23:31:41.947678Z"
        },
        "id": "yVDBM35-nfR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 1: SETUP & DATA ORGANIZATION (PATH CORRECTED)\n",
        "# ==============================================================================\n",
        "print(\"Block 1: Setting up the environment and organizing data...\")\n",
        "\n",
        "# --- Stage 1.1: Import Libraries ---\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, DenseNet121\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:07:59.001748Z",
          "iopub.execute_input": "2025-07-18T21:07:59.002036Z",
          "iopub.status.idle": "2025-07-18T21:08:20.215753Z",
          "shell.execute_reply.started": "2025-07-18T21:07:59.002011Z",
          "shell.execute_reply": "2025-07-18T21:08:20.214485Z"
        },
        "id": "setcZy8GnfR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "5LkX9cSGnfR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 1.2: Define Paths ---\n",
        "# Path has been corrected based on your screenshot.\n",
        "# We are starting with the images from the 'batch1_1' folder.\n",
        "BASE_DATA_PATH = \"/kaggle/input/high-quality-invoice-images-for-ocr/batch_1/batch_1/batch1_1\" # <-- PATH CORRECTED\n",
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "PROCESSED_DATA_PATH = os.path.join(WORKING_DIR, \"processed_data\")\n",
        "\n",
        "print(f\"Attempting to read from base data path: {BASE_DATA_PATH}\")\n",
        "print(f\"Working directory for output: {WORKING_DIR}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:08:20.217783Z",
          "iopub.execute_input": "2025-07-18T21:08:20.218319Z",
          "iopub.status.idle": "2025-07-18T21:08:20.225796Z",
          "shell.execute_reply.started": "2025-07-18T21:08:20.218297Z",
          "shell.execute_reply": "2025-07-18T21:08:20.224293Z"
        },
        "id": "T3iNfsh5nfR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 1.3: Create Directories for our new Dataset ---\n",
        "NOT_FRAUD_DIR = os.path.join(PROCESSED_DATA_PATH, \"not_fraud\")\n",
        "FRAUD_DIR = os.path.join(PROCESSED_DATA_PATH, \"fraud\")\n",
        "\n",
        "if os.path.exists(PROCESSED_DATA_PATH):\n",
        "    shutil.rmtree(PROCESSED_DATA_PATH)\n",
        "os.makedirs(NOT_FRAUD_DIR, exist_ok=True)\n",
        "os.makedirs(FRAUD_DIR, exist_ok=True)\n",
        "print(f\"Created directories for processed data at: {PROCESSED_DATA_PATH}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:08:20.227121Z",
          "iopub.execute_input": "2025-07-18T21:08:20.227474Z",
          "iopub.status.idle": "2025-07-18T21:08:20.254031Z",
          "shell.execute_reply.started": "2025-07-18T21:08:20.22745Z",
          "shell.execute_reply": "2025-07-18T21:08:20.252911Z"
        },
        "id": "tVMnx2YLnfR4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 1.4: Copy Original Images and Validate ---\n",
        "try:\n",
        "    if os.path.exists(BASE_DATA_PATH) and os.path.isdir(BASE_DATA_PATH):\n",
        "        original_image_files = [f for f in os.listdir(BASE_DATA_PATH) if f.endswith('.jpg')]\n",
        "        for file_name in original_image_files:\n",
        "            shutil.copy(os.path.join(BASE_DATA_PATH, file_name), NOT_FRAUD_DIR)\n",
        "\n",
        "        num_copied_files = len(os.listdir(NOT_FRAUD_DIR))\n",
        "        print(f\"Successfully copied {num_copied_files} original images to the 'not_fraud' directory.\")\n",
        "\n",
        "        # --- Stage 1.5: Validate and Explore Sample ---\n",
        "        if num_copied_files == 0:\n",
        "            print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "            print(\"!!! ERROR: The source directory was found, but it contains no .jpg files.  !!!\")\n",
        "            print(f\"!!! Please check the contents of: {BASE_DATA_PATH} !!!\")\n",
        "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        else:\n",
        "            print(\"Displaying a sample legitimate invoice...\")\n",
        "            sample_image_path = os.path.join(NOT_FRAUD_DIR, random.choice(os.listdir(NOT_FRAUD_DIR)))\n",
        "            sample_image = Image.open(sample_image_path)\n",
        "            plt.figure(figsize=(8, 10))\n",
        "            plt.imshow(sample_image)\n",
        "            plt.title(\"Sample Legitimate Invoice\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        print(\"!!! ERROR: The specified BASE_DATA_PATH does not exist or is not a directory. !!!\")\n",
        "        print(f\"!!! Please check the path: {BASE_DATA_PATH} !!!\")\n",
        "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Block 1 Execution Finished ---\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:09:27.052425Z",
          "iopub.execute_input": "2025-07-18T21:09:27.052829Z",
          "iopub.status.idle": "2025-07-18T21:09:35.103687Z",
          "shell.execute_reply.started": "2025-07-18T21:09:27.052799Z",
          "shell.execute_reply": "2025-07-18T21:09:35.102617Z"
        },
        "id": "r3ZfoKuBnfR4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# BLOCK 2: SYNTHETIC FRAUD GENERATION (REVISED)\n",
        "# ==============================================================================\n",
        "#\n",
        "# INDUSTRY INSIGHT (REVISED):\n",
        "# Our first attempt at data generation was too subtle. The model failed to learn.\n",
        "# We will now create much more obvious visual anomalies. This gives the model a\n",
        "# stronger, clearer signal to learn from, which is often necessary when a\n",
        "# model struggles to converge. We are making the difference between \"fraud\" and\n",
        "# \"not_fraud\" unmistakable.\n",
        "#\n",
        "print(\"\\nBlock 2 (Revised): Generating new, more obvious fraudulent data...\")\n",
        "\n",
        "# --- Stage 2.1: Define NEW Fraud Generation Functions ---\n",
        "\n",
        "def add_black_bars(image_path, output_path):\n",
        "    \"\"\"\n",
        "    Simulates redacting information with a thick black marker. This is a\n",
        "    very strong and obvious visual artifact for the model to detect.\n",
        "    \"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.convert(\"RGB\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        img_w, img_h = img.size\n",
        "\n",
        "        # Draw 1 to 3 black bars in random positions\n",
        "        for _ in range(random.randint(1, 3)):\n",
        "            # Choose a random position and size\n",
        "            bar_x = random.randint(int(img_w * 0.1), int(img_w * 0.8))\n",
        "            bar_y = random.randint(int(img_h * 0.1), int(img_h * 0.8))\n",
        "            bar_w = int(img_w * random.uniform(0.2, 0.5))\n",
        "            bar_h = int(img_h * random.uniform(0.03, 0.06))\n",
        "            draw.rectangle([bar_x, bar_y, bar_x + bar_w, bar_y + bar_h], fill=\"black\")\n",
        "\n",
        "        img.save(output_path, \"JPEG\")\n",
        "\n",
        "def add_void_stamp(image_path, output_path):\n",
        "    \"\"\"\n",
        "    Adds a large, semi-transparent \"VOID\" or \"FAKE\" stamp across the image.\n",
        "    This is another unmistakable sign of an altered document.\n",
        "    \"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "        # Create a transparent layer for the stamp\n",
        "        stamp_layer = Image.new(\"RGBA\", img.size, (255, 255, 255, 0))\n",
        "        draw = ImageDraw.Draw(stamp_layer)\n",
        "        img_w, img_h = img.size\n",
        "\n",
        "        # Load a large font\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=int(img_w / 6))\n",
        "        except IOError:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        # Choose stamp text and color\n",
        "        stamp_text = random.choice([\"VOID\", \"FAKE\", \"COPY\"])\n",
        "        text_color = (255, 0, 0, 100) # Red with alpha for transparency\n",
        "\n",
        "        # Calculate text size and position\n",
        "        text_bbox = draw.textbbox((0, 0), stamp_text, font=font)\n",
        "        text_w = text_bbox[2] - text_bbox[0]\n",
        "        text_h = text_bbox[3] - text_bbox[1]\n",
        "        pos_x = (img_w - text_w) / 2\n",
        "        pos_y = (img_h - text_h) / 2\n",
        "\n",
        "        # Draw the rotated text\n",
        "        draw.text((pos_x, pos_y), stamp_text, font=font, fill=text_color)\n",
        "\n",
        "        # Rotate the stamp layer\n",
        "        rotated_stamp = stamp_layer.rotate(30, expand=0)\n",
        "\n",
        "        # Composite the stamp onto the original image\n",
        "        img.paste(rotated_stamp, (0, 0), rotated_stamp)\n",
        "        img.save(output_path, \"JPEG\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:09:55.358269Z",
          "iopub.execute_input": "2025-07-18T21:09:55.359602Z",
          "iopub.status.idle": "2025-07-18T21:09:55.376939Z",
          "shell.execute_reply.started": "2025-07-18T21:09:55.359537Z",
          "shell.execute_reply": "2025-07-18T21:09:55.375985Z"
        },
        "id": "gCAHgbKvnfR5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 2.2: Generate the NEW Fraudulent Images ---\n",
        "# First, we must clean the old fraud images\n",
        "if os.path.exists(FRAUD_DIR):\n",
        "    shutil.rmtree(FRAUD_DIR)\n",
        "os.makedirs(FRAUD_DIR, exist_ok=True)\n",
        "print(f\"Cleaned old fraud data and recreated directory: {FRAUD_DIR}\")\n",
        "\n",
        "source_images = os.listdir(NOT_FRAUD_DIR)\n",
        "num_fraud_images_to_generate = len(source_images)\n",
        "\n",
        "print(f\"Starting generation of {num_fraud_images_to_generate} new fraudulent images...\")\n",
        "\n",
        "for i in range(num_fraud_images_to_generate):\n",
        "    source_image_name = random.choice(source_images)\n",
        "    source_image_path = os.path.join(NOT_FRAUD_DIR, source_image_name)\n",
        "\n",
        "    output_image_name = f\"fraud_{i}_{source_image_name}\"\n",
        "    output_image_path = os.path.join(FRAUD_DIR, output_image_name)\n",
        "\n",
        "    # Use our new, more obvious techniques\n",
        "    technique = random.choice([add_black_bars, add_void_stamp])\n",
        "    try:\n",
        "        technique(source_image_path, output_image_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate image {output_image_name} due to error: {e}\")\n",
        "\n",
        "print(f\"Successfully generated {len(os.listdir(FRAUD_DIR))} new synthetic fraudulent images.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:10:02.000716Z",
          "iopub.execute_input": "2025-07-18T21:10:02.001045Z",
          "iopub.status.idle": "2025-07-18T21:10:48.415908Z",
          "shell.execute_reply.started": "2025-07-18T21:10:02.001022Z",
          "shell.execute_reply": "2025-07-18T21:10:48.414676Z"
        },
        "id": "g1Ej6iGDnfR5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 2.3: Explore a Sample of the NEW Fraudulent Invoices ---\n",
        "print(\"Displaying a sample of the new fraudulent invoices...\")\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "try:\n",
        "    # Show one of each type\n",
        "    sample_bar_path = None\n",
        "    sample_stamp_path = None\n",
        "\n",
        "    fraud_files = os.listdir(FRAUD_DIR)\n",
        "    random.shuffle(fraud_files)\n",
        "\n",
        "    for fname in fraud_files:\n",
        "        if \"fraud\" in fname and sample_bar_path is None:\n",
        "             # Just pick a random one, as we don't store the type in the name\n",
        "             # We'll rely on the visual difference\n",
        "             sample_bar_path = os.path.join(FRAUD_DIR, fname)\n",
        "        if \"fraud\" in fname and sample_stamp_path is None and fname != os.path.basename(sample_bar_path):\n",
        "             sample_stamp_path = os.path.join(FRAUD_DIR, fname)\n",
        "        if sample_bar_path and sample_stamp_path:\n",
        "            break\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(Image.open(sample_bar_path))\n",
        "    plt.title(\"Sample: Black Bar Redaction\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(Image.open(sample_stamp_path))\n",
        "    plt.title(\"Sample: VOID Stamp\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not display sample fraud images. Error: {e}\")\n",
        "\n",
        "print(\"\\n--- Block 2 (Revised) Execution Finished ---\")\n",
        "print(\"\\nIMPORTANT: Now you must re-run Block 3, Block 4, and Block 5 to train the models on this new data.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:12:55.212913Z",
          "iopub.execute_input": "2025-07-18T21:12:55.21334Z",
          "iopub.status.idle": "2025-07-18T21:12:56.36079Z",
          "shell.execute_reply.started": "2025-07-18T21:12:55.213302Z",
          "shell.execute_reply": "2025-07-18T21:12:56.359458Z"
        },
        "id": "fOzk7BlpnfR5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBlock 3: Setting up the model training framework...\")\n",
        "\n",
        "# --- Stage 3.1: Define Hyperparameters ---\n",
        "# These settings are crucial for model performance. We choose values that\n",
        "# are known to work well for transfer learning tasks.\n",
        "IMG_SIZE = (224, 224)  # The standard input size for many pre-trained models.\n",
        "BATCH_SIZE = 32        # Number of images to process at a time.\n",
        "EPOCHS = 8             # We'll keep this low for fast training. EarlyStopping will quit sooner if needed.\n",
        "LEARNING_RATE = 0.001  # A common and effective learning rate for the Adam optimizer."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:13:15.586911Z",
          "iopub.execute_input": "2025-07-18T21:13:15.587317Z",
          "iopub.status.idle": "2025-07-18T21:13:15.593658Z",
          "shell.execute_reply.started": "2025-07-18T21:13:15.587287Z",
          "shell.execute_reply": "2025-07-18T21:13:15.592693Z"
        },
        "id": "Fb7IMxaFnfR6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 3.2: Create Data Generators ---\n",
        "# ImageDataGenerator is a powerful Keras utility to load and augment image data.\n",
        "# Augmentation (like rotation, zoom) creates more diverse training examples,\n",
        "# making the final model more robust to variations in real-world data.\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,          # Normalize pixel values from [0, 255] to [0, 1]\n",
        "    validation_split=0.2,     # Reserve 20% of the data for validation\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=False,    # Flipping an invoice horizontally doesn't make sense\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Generator for the training data (uses 80% of images)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    PROCESSED_DATA_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',      # It's a two-class problem: fraud vs. not_fraud\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Generator for the validation data (uses 20% of images)\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    PROCESSED_DATA_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Found {train_generator.n} images for training.\")\n",
        "print(f\"Found {validation_generator.n} images for validation.\")\n",
        "print(f\"Classes: {train_generator.class_indices}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:13:21.423935Z",
          "iopub.execute_input": "2025-07-18T21:13:21.424272Z",
          "iopub.status.idle": "2025-07-18T21:13:21.46149Z",
          "shell.execute_reply.started": "2025-07-18T21:13:21.42425Z",
          "shell.execute_reply": "2025-07-18T21:13:21.46036Z"
        },
        "id": "3smo4rNWnfR6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 3.3: Define a Reusable Model Creation and Training Function ---\n",
        "def create_and_train_model(base_model_class, model_name, train_gen, val_gen):\n",
        "    \"\"\"\n",
        "    Builds, compiles, and trains a model using a given base architecture.\n",
        "\n",
        "    Args:\n",
        "        base_model_class: The Keras pre-trained model class (e.g., MobileNetV2).\n",
        "        model_name (str): A name for the model, used for saving files.\n",
        "        train_gen: The data generator for training.\n",
        "        val_gen: The data generator for validation.\n",
        "\n",
        "    Returns:\n",
        "        A tuple of (trained model, training history).\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Training Model: {model_name} ---\")\n",
        "\n",
        "    # 1. Load the base model with pre-trained ImageNet weights, without the top layer.\n",
        "    base_model = base_model_class(input_shape=IMG_SIZE + (3,),\n",
        "                                  include_top=False,\n",
        "                                  weights='imagenet')\n",
        "    # 2. Freeze the base model's layers. We don't want to change its learned features yet.\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Add our custom classification head. This is the part we will train.\n",
        "    inputs = Input(shape=IMG_SIZE + (3,))\n",
        "    x = base_model(inputs, training=False) # Run in inference mode.\n",
        "    x = GlobalAveragePooling2D()(x)        # Flattens the features.\n",
        "    x = Dropout(0.3)(x)                    # Regularization to prevent overfitting.\n",
        "    x = Dense(128, activation='relu')(x)   # A hidden layer.\n",
        "    outputs = Dense(1, activation='sigmoid')(x) # Output layer for binary classification.\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # 4. Compile the model.\n",
        "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(f\"Model architecture for {model_name} created.\")\n",
        "    model.summary()\n",
        "\n",
        "    # 5. Set up callbacks for robust training.\n",
        "    # ModelCheckpoint saves the best version of the model during training.\n",
        "    checkpoint_path = os.path.join(WORKING_DIR, f\"{model_name}_best.h5\")\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path,\n",
        "                                 save_best_only=True,\n",
        "                                 monitor='val_accuracy',\n",
        "                                 mode='max',\n",
        "                                 verbose=1)\n",
        "    # EarlyStopping stops training if performance doesn't improve.\n",
        "    early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                                   patience=3, # Stop after 3 epochs of no improvement.\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "    # 6. Train the model.\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    print(f\"--- Finished training {model_name} ---\")\n",
        "    return model, history"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:13:26.486043Z",
          "iopub.execute_input": "2025-07-18T21:13:26.486444Z",
          "iopub.status.idle": "2025-07-18T21:13:26.497266Z",
          "shell.execute_reply.started": "2025-07-18T21:13:26.486418Z",
          "shell.execute_reply": "2025-07-18T21:13:26.495911Z"
        },
        "id": "DH5FzwFynfR6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Stage 3.4: Define a Plotting Function ---\n",
        "def plot_history(history, model_name):\n",
        "    \"\"\"Plots the training and validation accuracy and loss.\"\"\"\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title(f'{model_name} - Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(f'{model_name} - Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n--- Block 3 Execution Finished ---\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:13:35.732773Z",
          "iopub.execute_input": "2025-07-18T21:13:35.733188Z",
          "iopub.status.idle": "2025-07-18T21:13:35.741594Z",
          "shell.execute_reply.started": "2025-07-18T21:13:35.733155Z",
          "shell.execute_reply": "2025-07-18T21:13:35.740455Z"
        },
        "id": "CK2S3NHlnfR6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# BLOCK 4: MODEL TRAINING EXECUTION\n",
        "# ==============================================================================\n",
        "#\n",
        "# INDUSTRY INSIGHT:\n",
        "# This is where the main experiment happens. We will now use the functions\n",
        "# from Block 3 to train each of our candidate models sequentially. We'll store\n",
        "# the results of each training run so we can compare them at the end.\n",
        "#\n",
        "print(\"\\nBlock 4: Executing the training for all candidate models...\")\n",
        "\n",
        "# --- Stage 4.1: Train the Models ---\n",
        "# We will create a dictionary to hold the training history of each model.\n",
        "model_histories = {}\n",
        "\n",
        "# --- Train MobileNetV2 ---\n",
        "mobilenet_model, mobilenet_history = create_and_train_model(\n",
        "    base_model_class=MobileNetV2,\n",
        "    model_name=\"MobileNetV2\",\n",
        "    train_gen=train_generator,\n",
        "    val_gen=validation_generator\n",
        ")\n",
        "model_histories['MobileNetV2'] = mobilenet_history\n",
        "plot_history(mobilenet_history, \"MobileNetV2\")\n",
        "\n",
        "\n",
        "# --- Train EfficientNetB0 ---\n",
        "efficientnet_model, efficientnet_history = create_and_train_model(\n",
        "    base_model_class=EfficientNetB0,\n",
        "    model_name=\"EfficientNetB0\",\n",
        "    train_gen=train_generator,\n",
        "    val_gen=validation_generator\n",
        ")\n",
        "model_histories['EfficientNetB0'] = efficientnet_history\n",
        "plot_history(efficientnet_history, \"EfficientNetB0\")\n",
        "\n",
        "\n",
        "# --- Train DenseNet121 ---\n",
        "densenet_model, densenet_history = create_and_train_model(\n",
        "    base_model_class=DenseNet121,\n",
        "    model_name=\"DenseNet121\",\n",
        "    train_gen=train_generator,\n",
        "    val_gen=validation_generator\n",
        ")\n",
        "model_histories['DenseNet121'] = densenet_history\n",
        "plot_history(densenet_history, \"DenseNet121\")\n",
        "\n",
        "\n",
        "print(\"\\n--- All models have been trained. ---\")\n",
        "print(\"The best version of each model has been saved to a .h5 file in the /kaggle/working/ directory.\")\n",
        "print(\"\\n--- Block 4 Execution Finished ---\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:13:42.464447Z",
          "iopub.execute_input": "2025-07-18T21:13:42.465657Z",
          "iopub.status.idle": "2025-07-18T21:40:23.834383Z",
          "shell.execute_reply.started": "2025-07-18T21:13:42.465616Z",
          "shell.execute_reply": "2025-07-18T21:40:23.83317Z"
        },
        "id": "dz0pLetAnfR7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#BLOCK 5: FINE-TUNING THE BEST PERFORMING MODEL\n",
        "# ==============================================================================\n",
        "#\n",
        "# INDUSTRY INSIGHT:\n",
        "# The initial training (Block 4) gave poor results because the pre-trained\n",
        "# base model is frozen. Its features are general-purpose. Now, we perform\n",
        "# fine-tuning. We unfreeze the top layers of the base model and retrain with a\n",
        "# very low learning rate. This allows the model to adapt its specialized\n",
        "# feature detectors to our specific dataset (invoices) without corrupting\n",
        "# its valuable pre-trained knowledge. This is a critical step for achieving\n",
        "# high accuracy in transfer learning.\n",
        "#\n",
        "print(\"\\nBlock 5: Fine-tuning the best model (MobileNetV2)...\")\n",
        "\n",
        "# --- Stage 5.1: Load the Best Saved Model ---\n",
        "# We start from the best weights we saved during the initial training phase.\n",
        "best_model_path = os.path.join(WORKING_DIR, \"MobileNetV2_best.h5\")\n",
        "model_to_fine_tune = tf.keras.models.load_model(best_model_path)\n",
        "\n",
        "print(\"Successfully loaded the best MobileNetV2 model for fine-tuning.\")\n",
        "\n",
        "# --- Stage 5.2: Unfreeze Layers of the Base Model ---\n",
        "# We need to access the original base model within our loaded model.\n",
        "# It's usually the second layer (index 1), after the Input layer.\n",
        "base_model = model_to_fine_tune.layers[1]\n",
        "base_model.trainable = True\n",
        "\n",
        "# We'll unfreeze the top layers and keep the bottom ones frozen.\n",
        "# The bottom layers detect very simple features (edges, colors), which are\n",
        "# universal. The top layers detect more complex features (shapes, textures)\n",
        "# which we want to adapt.\n",
        "fine_tune_at = 100 # Unfreeze from the 100th layer onwards.\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(f\"Unfroze layers from layer {fine_tune_at} onwards in the base model.\")\n",
        "\n",
        "# --- Stage 5.3: Re-compile the Model with a Low Learning Rate ---\n",
        "# This is CRITICAL. Using a low learning rate prevents the model from\n",
        "# destroying the pre-trained weights with large updates.\n",
        "LOW_LEARNING_RATE = 0.00001\n",
        "\n",
        "model_to_fine_tune.compile(\n",
        "    optimizer=Adam(learning_rate=LOW_LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_to_fine_tune.summary()\n",
        "\n",
        "# --- Stage 5.4: Continue Training (Fine-Tuning) ---\n",
        "# We'll train for a few more epochs to let the model adapt.\n",
        "fine_tune_epochs = 10\n",
        "total_epochs = EPOCHS + fine_tune_epochs\n",
        "\n",
        "print(\"\\nStarting fine-tuning...\")\n",
        "\n",
        "history_fine_tune = model_to_fine_tune.fit(\n",
        "    train_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=mobilenet_history.epoch[-1] + 1, # Start from where we left off\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[ # We can reuse the same callbacks\n",
        "        ModelCheckpoint(os.path.join(WORKING_DIR, \"MobileNetV2_finetuned_best.h5\"),\n",
        "                        save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"--- Finished fine-tuning ---\")\n",
        "\n",
        "# --- Stage 5.5: Visualize the Fine-Tuning Results ---\n",
        "# We can append the fine-tuning history to the original history for a complete plot.\n",
        "mobilenet_history.history['accuracy'].extend(history_fine_tune.history['accuracy'])\n",
        "mobilenet_history.history['val_accuracy'].extend(history_fine_tune.history['val_accuracy'])\n",
        "mobilenet_history.history['loss'].extend(history_fine_tune.history['loss'])\n",
        "mobilenet_history.history['val_loss'].extend(history_fine_tune.history['val_loss'])\n",
        "\n",
        "plot_history(mobilenet_history, \"MobileNetV2 (with Fine-Tuning)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Block 5 Execution Finished ---\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T21:56:02.779757Z",
          "iopub.execute_input": "2025-07-18T21:56:02.780114Z",
          "iopub.status.idle": "2025-07-18T22:00:34.428017Z",
          "shell.execute_reply.started": "2025-07-18T21:56:02.780091Z",
          "shell.execute_reply": "2025-07-18T22:00:34.426742Z"
        },
        "id": "HdwroP-_nfR7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# STEP 1: RESTORE SAVED MODELS\n",
        "# =======================================================\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- DEBUGGING: List available input directories ---\n",
        "# This will help you find the correct folder name for your saved models.\n",
        "print(\"Searching for your saved model directory...\")\n",
        "print(\"Available directories in /kaggle/input/:\")\n",
        "try:\n",
        "    for item in os.listdir(\"/kaggle/input/\"):\n",
        "        print(f\"  - {item}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Could not find the /kaggle/input/ directory.\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- PASTE YOUR CORRECT PATH HERE ---\n",
        "# Look at the list above. Find the directory that looks like your notebook's name.\n",
        "# Copy that name and append it to \"/kaggle/input/\".\n",
        "# For example, if you see '- invoicefrauddetection', your path should be '/kaggle/input/invoicefrauddetection/'\n",
        "INPUT_MODEL_PATH = \"/kaggle/input/invoicefrauddetection/\" # <-- REPLACE THIS VALUE\n",
        "OUTPUT_MODEL_PATH = \"/kaggle/working/\"\n",
        "\n",
        "print(f\"Attempting to copy models from: {INPUT_MODEL_PATH}\")\n",
        "\n",
        "try:\n",
        "    # Create the destination directory if it doesn't exist\n",
        "    os.makedirs(OUTPUT_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "    # Copy the model files\n",
        "    shutil.copy(os.path.join(INPUT_MODEL_PATH, \"MobileNetV2_best.h5\"), OUTPUT_MODEL_PATH)\n",
        "    shutil.copy(os.path.join(INPUT_MODEL_PATH, \"DenseNet121_best.h5\"), OUTPUT_MODEL_PATH)\n",
        "\n",
        "    print(\"\\nModels restored successfully!\")\n",
        "    print(\"Files in current working directory:\", os.listdir(OUTPUT_MODEL_PATH))\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nERROR: Could not find the model files.\")\n",
        "    print(\"Please look at the list of 'Available directories' printed above.\")\n",
        "    print(\"Update the INPUT_MODEL_PATH variable with the correct path and re-run this cell.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T23:53:00.969809Z",
          "iopub.execute_input": "2025-07-18T23:53:00.970092Z",
          "iopub.status.idle": "2025-07-18T23:53:01.771471Z",
          "shell.execute_reply.started": "2025-07-18T23:53:00.970071Z",
          "shell.execute_reply": "2025-07-18T23:53:01.770371Z"
        },
        "id": "HBKpqehSnfR7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL BLOCK: LAUNCH THE WEB APPLICATION WITH A PUBLIC URL\n",
        "# ==============================================================================\n",
        "#\n",
        "# INDUSTRY INSIGHT:\n",
        "# When running a web server inside a cloud environment like Kaggle or Colab,\n",
        "# the default URLs (like localhost) are not accessible from the public internet.\n",
        "# We need to use a tunneling service to create a secure public URL that forwards\n",
        "# traffic to our application. `ngrok` is the industry standard for this.\n",
        "#\n",
        "print(\"Final Block: Installing libraries and launching the app with a public tunnel...\")\n",
        "\n",
        "# --- Step 1: Install necessary libraries ---\n",
        "# We use -q to make the output less noisy (quiet mode)\n",
        "!pip install -q streamlit pyngrok\n",
        "\n",
        "# --- Step 2: Write the app.py file (if not already done) ---\n",
        "# This ensures the app file exists before we try to run it.\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "st.set_page_config(page_title=\"Invoice Fraud Detector\", page_icon=\"ðŸ•µï¸\", layout=\"centered\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_keras_model(model_path):\n",
        "    try:\n",
        "        return tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model {os.path.basename(model_path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "st.title(\"Invoice Fraud Detection ðŸ•µï¸\")\n",
        "st.write('''\n",
        "This application uses deep learning to determine if an uploaded invoice image\n",
        "shows signs of visual tampering (fraud). Choose a model and upload an image to get a prediction.\n",
        "''')\n",
        "\n",
        "MODEL_DIR = \"/kaggle/working/\"\n",
        "MODEL_FILES = {\n",
        "    \"MobileNetV2\": os.path.join(MODEL_DIR, \"MobileNetV2_best.h5\"),\n",
        "    \"DenseNet121\": os.path.join(MODEL_DIR, \"DenseNet121_best.h5\")\n",
        "}\n",
        "\n",
        "available_models = [name for name, path in MODEL_FILES.items() if os.path.exists(path)]\n",
        "\n",
        "if not available_models:\n",
        "    st.error(\"Could not find any trained model files. Please ensure the training blocks have been run successfully.\")\n",
        "else:\n",
        "    model_name = st.selectbox(\"Choose a detection model:\", available_models)\n",
        "    uploaded_file = st.file_uploader(\"Upload an invoice image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "\n",
        "        # Display the uploaded image (FIXED: use_container_width)\n",
        "        st.image(image, caption=\"Uploaded Invoice\", use_container_width=True)\n",
        "\n",
        "        image_resized = image.resize((224, 224))\n",
        "        image_array = np.array(image_resized) / 255.0\n",
        "        image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "        with st.spinner(f\"Loading {model_name} and analyzing image...\"):\n",
        "            model = load_keras_model(MODEL_FILES[model_name])\n",
        "            if model:\n",
        "                prediction = model.predict(image_array)\n",
        "                score = prediction[0][0]\n",
        "                st.subheader(\"Analysis Complete!\")\n",
        "                if score > 0.5:\n",
        "                    st.success(f\"**Result:** This invoice appears to be **LEGITIMATE**.\")\n",
        "                    st.metric(label=f\"Confidence (Legitimate)\", value=f\"{score:.2%}\")\n",
        "                else:\n",
        "                    st.error(f\"**Result:** This invoice shows signs of **FRAUD!**\")\n",
        "                    st.metric(label=f\"Confidence (Fraudulent)\", value=f\"{1 - score:.2%}\")\n",
        "                with st.expander(\"See model output details\"):\n",
        "                    st.write(f\"Model: `{model_name}` | Raw score: `{score:.4f}`\")\n",
        "\"\"\"\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# --- Step 3: Authenticate and Run ngrok ---\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# !! IMPORTANT !!\n",
        "# 1. Go to https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# 2. Copy your authtoken.\n",
        "# 3. Paste it below, replacing \"YOUR_AUTHTOKEN_HERE\".\n",
        "NGROK_AUTH_TOKEN = \"304BU2pMYLdmOKmW4bS0mBNrKxJ_B4PrzzQXQNQdbCm35SyD\"\n",
        "\n",
        "if NGROK_AUTH_TOKEN == \"YOUR_AUTHTOKEN_HERE\":\n",
        "    print(\"ERROR: Please paste your ngrok authtoken into the NGROK_AUTH_TOKEN variable.\")\n",
        "else:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    ngrok.kill() # Terminate any existing tunnels\n",
        "\n",
        "    print(\"Starting Streamlit server in the background...\")\n",
        "    proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n",
        "\n",
        "    print(\"Waiting for server to start...\")\n",
        "    time.sleep(10)\n",
        "\n",
        "    print(\"Creating public tunnel with ngrok...\")\n",
        "    try:\n",
        "        public_url = ngrok.connect(8501)\n",
        "        print(\"\\n\\n====================================================================\")\n",
        "        print(\"CONGRATULATIONS! Your app is live.\")\n",
        "        print(\"Click the link below to open it in a new tab:\")\n",
        "        print(public_url)\n",
        "        print(\"====================================================================\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred with ngrok: {e}\")\n",
        "        print(\"Please ensure your authtoken is correct.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T23:54:19.910199Z",
          "iopub.execute_input": "2025-07-18T23:54:19.910555Z",
          "iopub.status.idle": "2025-07-18T23:54:35.405778Z",
          "shell.execute_reply.started": "2025-07-18T23:54:19.910531Z",
          "shell.execute_reply": "2025-07-18T23:54:35.404544Z"
        },
        "id": "BGsmAh5gnfR7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nLBPQMypnfR8"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}